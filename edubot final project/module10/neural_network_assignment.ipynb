{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc18b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e93d10",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine dataset from sklearn\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Number of classes:\", len(np.unique(y)))\n",
    "print(\"Feature names:\", wine_data.feature_names[:5])  # Show first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Original data range - Min:\", X.min(), \"Max:\", X.max())\n",
    "print(\"Scaled data range - Min:\", X_scaled.min(), \"Max:\", X_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dddcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b6ddb",
   "metadata": {},
   "source": [
    "# 2. Understanding Neural Network Basics\n",
    "\n",
    "**Components of a Neural Network:**\n",
    "- **Input Layer**: Receives the input features (13 features for wine dataset)\n",
    "- **Hidden Layers**: Process the data through weights and biases with activation functions\n",
    "- **Output Layer**: Produces final predictions (3 classes for wine types)\n",
    "\n",
    "**Key Elements:**\n",
    "- **Weights**: Connect neurons and determine importance of inputs\n",
    "- **Biases**: Add flexibility to the model\n",
    "- **Activation Functions**: Add non-linearity (ReLU, Sigmoid, Softmax)\n",
    "- **Loss Function**: Measures prediction errors\n",
    "- **Optimizer**: Updates weights to minimize loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf826d9",
   "metadata": {},
   "source": [
    "# 3. Model Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model using Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(64, input_shape=(13,), activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8edddd",
   "metadata": {},
   "source": [
    "# 4. Model Compilation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeda6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',    # Loss function for multi-class classification\n",
    "    optimizer='adam',                   # Adam optimizer\n",
    "    metrics=['accuracy']                # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04270e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82094b",
   "metadata": {},
   "source": [
    "# 5. Evaluation & Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Sample predictions (first 10):\")\n",
    "print(\"Predicted:\", predicted_classes[:10])\n",
    "print(\"Actual   :\", y_test[:10])\n",
    "print(\"Match    :\", predicted_classes[:10] == y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe08c0",
   "metadata": {},
   "source": [
    "**Training Curve Interpretation:**\n",
    "- If training and validation curves are close: Good fit\n",
    "- If training loss much lower than validation loss: Overfitting\n",
    "- If both training and validation loss are high: Underfitting\n",
    "- Decreasing loss over epochs shows learning progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ea130",
   "metadata": {},
   "source": [
    "**Training Curve Interpretation:**\n",
    "- If training and validation curves are close: Good fit\n",
    "- If training loss much lower than validation loss: Overfitting\n",
    "- If both training and validation loss are high: Underfitting\n",
    "- Decreasing loss over epochs shows learning progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5284c8",
   "metadata": {},
   "source": [
    "# 6. Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c70fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Model with more hidden layers\n",
    "model_exp1 = Sequential()\n",
    "model_exp1.add(Dense(128, input_shape=(13,), activation='relu'))\n",
    "model_exp1.add(Dense(64, activation='relu'))\n",
    "model_exp1.add(Dense(32, activation='relu'))\n",
    "model_exp1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_exp1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_exp1 = model_exp1.fit(X_train, y_train_cat, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "test_loss_exp1, test_accuracy_exp1 = model_exp1.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(\"Experiment 1 - More layers:\")\n",
    "print(\"Test Accuracy:\", test_accuracy_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Model with different activation function (tanh)\n",
    "model_exp2 = Sequential()\n",
    "model_exp2.add(Dense(64, input_shape=(13,), activation='tanh'))\n",
    "model_exp2.add(Dense(32, activation='tanh'))\n",
    "model_exp2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_exp2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_exp2 = model_exp2.fit(X_train, y_train_cat, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "test_loss_exp2, test_accuracy_exp2 = model_exp2.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(\"Experiment 2 - Tanh activation:\")\n",
    "print(\"Test Accuracy:\", test_accuracy_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Model with fewer neurons\n",
    "model_exp3 = Sequential()\n",
    "model_exp3.add(Dense(16, input_shape=(13,), activation='relu'))\n",
    "model_exp3.add(Dense(8, activation='relu'))\n",
    "model_exp3.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_exp3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_exp3 = model_exp3.fit(X_train, y_train_cat, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "test_loss_exp3, test_accuracy_exp3 = model_exp3.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(\"Experiment 3 - Fewer neurons:\")\n",
    "print(\"Test Accuracy:\", test_accuracy_exp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5803d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model performances\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"Original Model:\", test_accuracy)\n",
    "print(\"More Layers   :\", test_accuracy_exp1)\n",
    "print(\"Tanh Activation:\", test_accuracy_exp2)\n",
    "print(\"Fewer Neurons :\", test_accuracy_exp3)\n",
    "\n",
    "# Create comparison plot\n",
    "models = ['Original', 'More Layers', 'Tanh Activation', 'Fewer Neurons']\n",
    "accuracies = [test_accuracy, test_accuracy_exp1, test_accuracy_exp2, test_accuracy_exp3]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracies)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
