{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832177f7",
   "metadata": {},
   "source": [
    "# ML Model Deployment Project\n",
    "\n",
    "This notebook will help you build, save, and deploy a machine learning model using Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000369f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install packages one by one\n",
    "packages = ['pandas', 'scikit-learn', 'joblib', 'streamlit', 'matplotlib', 'seaborn']\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
    "print(\"All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424374ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd2249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 5)\n",
      "Dataset columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n",
      "First 5 rows:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset from sklearn\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"Dataset columns:\", data.columns.tolist())\n",
    "print(\"First 5 rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bc6f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (120, 4)\n",
      "Testing set size: (30, 4)\n",
      "Target classes: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for machine learning\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n",
    "print(\"Target classes:\", iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec89521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model trained successfully\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3939259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: iris_model.pkl\n",
      "Model info saved as: model_info.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_filename = 'iris_model.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "# Also save the feature names and target names for later use\n",
    "model_info = {\n",
    "    'feature_names': iris.feature_names,\n",
    "    'target_names': iris.target_names\n",
    "}\n",
    "joblib.dump(model_info, 'model_info.pkl')\n",
    "\n",
    "print(\"Model saved as:\", model_filename)\n",
    "print(\"Model info saved as: model_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fca224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Sample input: [5.1, 3.5, 1.4, 0.2]\n",
      "Predicted class: setosa\n",
      "Prediction probabilities: [1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uday2\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\uday2\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('iris_model.pkl')\n",
    "loaded_model_info = joblib.load('model_info.pkl')\n",
    "\n",
    "# Test the loaded model with sample data\n",
    "sample_data = [[5.1, 3.5, 1.4, 0.2]]  # Sample iris flower measurements\n",
    "prediction = loaded_model.predict(sample_data)\n",
    "prediction_proba = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "print(\"Model loaded successfully\")\n",
    "print(\"Sample input:\", sample_data[0])\n",
    "print(\"Predicted class:\", loaded_model_info['target_names'][prediction[0]])\n",
    "print(\"Prediction probabilities:\", prediction_proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2640c642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app created as: streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "# Create Streamlit app code\n",
    "streamlit_app_code = '''\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the model and model info\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = joblib.load('iris_model.pkl')\n",
    "    model_info = joblib.load('model_info.pkl')\n",
    "    return model, model_info\n",
    "\n",
    "# Load model\n",
    "model, model_info = load_model()\n",
    "\n",
    "# App title\n",
    "st.title('Iris Flower Classifier')\n",
    "\n",
    "# App description\n",
    "st.write('This app predicts the species of iris flowers based on their measurements.')\n",
    "\n",
    "# Create input widgets\n",
    "st.sidebar.header('Input Features')\n",
    "\n",
    "sepal_length = st.sidebar.slider('Sepal Length (cm)', 4.0, 8.0, 5.0)\n",
    "sepal_width = st.sidebar.slider('Sepal Width (cm)', 2.0, 4.5, 3.0)\n",
    "petal_length = st.sidebar.slider('Petal Length (cm)', 1.0, 7.0, 4.0)\n",
    "petal_width = st.sidebar.slider('Petal Width (cm)', 0.1, 2.5, 1.0)\n",
    "\n",
    "# Create input array\n",
    "input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "\n",
    "# Display input values\n",
    "st.subheader('Input Values')\n",
    "st.write('Sepal Length:', sepal_length)\n",
    "st.write('Sepal Width:', sepal_width)\n",
    "st.write('Petal Length:', petal_length)\n",
    "st.write('Petal Width:', petal_width)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(input_data)\n",
    "prediction_proba = model.predict_proba(input_data)\n",
    "\n",
    "# Display prediction\n",
    "st.subheader('Prediction')\n",
    "predicted_species = model_info['target_names'][prediction[0]]\n",
    "st.write('Predicted Species:', predicted_species)\n",
    "\n",
    "# Display prediction probabilities\n",
    "st.subheader('Prediction Probabilities')\n",
    "for i, species in enumerate(model_info['target_names']):\n",
    "    st.write(f'{species}: {prediction_proba[0][i]:.3f}')\n",
    "'''\n",
    "\n",
    "# Save the Streamlit app to a Python file\n",
    "with open('streamlit_app.py', 'w') as f:\n",
    "    f.write(streamlit_app_code)\n",
    "\n",
    "print(\"Streamlit app created as: streamlit_app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aaf5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements file created: requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Create requirements.txt file\n",
    "requirements = '''pandas==2.0.3\n",
    "scikit-learn==1.3.0\n",
    "joblib==1.3.1\n",
    "streamlit==1.25.0\n",
    "numpy==1.24.3\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "'''\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"Requirements file created: requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2162641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README file created: README.md\n"
     ]
    }
   ],
   "source": [
    "# Create README.md file\n",
    "readme_content = '''# Iris Flower Classification Project\n",
    "\n",
    "## Overview\n",
    "This project builds a machine learning model to classify iris flowers into three species: setosa, versicolor, and virginica. The model uses flower measurements to make predictions.\n",
    "\n",
    "## Features\n",
    "- Machine learning model using Random Forest classifier\n",
    "- Streamlit web application for easy predictions\n",
    "- Model accuracy: 100% on test data\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Install Python 3.8 or higher\n",
    "2. Install required packages:\n",
    "   ```\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. Run the Streamlit app:\n",
    "   ```\n",
    "   streamlit run streamlit_app.py\n",
    "   ```\n",
    "\n",
    "## Input Examples\n",
    "The model expects four measurements:\n",
    "- Sepal Length: 4.0 - 8.0 cm\n",
    "- Sepal Width: 2.0 - 4.5 cm  \n",
    "- Petal Length: 1.0 - 7.0 cm\n",
    "- Petal Width: 0.1 - 2.5 cm\n",
    "\n",
    "## Sample Predictions\n",
    "- Input: [5.1, 3.5, 1.4, 0.2] -> Prediction: Setosa\n",
    "- Input: [6.0, 3.0, 4.5, 1.5] -> Prediction: Versicolor\n",
    "- Input: [6.5, 3.0, 5.5, 2.0] -> Prediction: Virginica\n",
    "\n",
    "## Files\n",
    "- iris_model.pkl: Trained machine learning model\n",
    "- model_info.pkl: Model metadata and class names\n",
    "- streamlit_app.py: Web application\n",
    "- requirements.txt: Required Python packages\n",
    "- ml_model_deployment.ipynb: Complete development notebook\n",
    "\n",
    "## Deployment\n",
    "This app can be deployed on cloud platforms like:\n",
    "- Streamlit Cloud\n",
    "- Heroku\n",
    "- AWS\n",
    "- Google Cloud Platform\n",
    "\n",
    "For Streamlit Cloud deployment:\n",
    "1. Upload files to GitHub repository\n",
    "2. Connect repository to Streamlit Cloud\n",
    "3. Deploy with one click\n",
    "'''\n",
    "\n",
    "with open('README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"README file created: README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba4bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROJECT COMPLETED SUCCESSFULLY ===\n",
      "Files created:\n",
      "1. iris_model.pkl - Trained machine learning model\n",
      "2. model_info.pkl - Model metadata\n",
      "3. streamlit_app.py - Web application\n",
      "4. requirements.txt - Dependencies list\n",
      "5. README.md - Project documentation\n",
      "\n",
      "To run the Streamlit app:\n",
      "1. Open terminal in this directory\n",
      "2. Run: streamlit run streamlit_app.py\n",
      "3. Open browser to the provided URL\n",
      "\n",
      "Model Performance:\n",
      "- Accuracy: 100% on test data\n",
      "- Dataset: Iris flowers (150 samples)\n",
      "- Features: 4 measurements\n",
      "- Classes: 3 species\n"
     ]
    }
   ],
   "source": [
    "# Project Summary\n",
    "print(\"=== PROJECT COMPLETED SUCCESSFULLY ===\")\n",
    "print(\"Files created:\")\n",
    "print(\"1. iris_model.pkl - Trained machine learning model\")\n",
    "print(\"2. model_info.pkl - Model metadata\")\n",
    "print(\"3. streamlit_app.py - Web application\")\n",
    "print(\"4. requirements.txt - Dependencies list\")\n",
    "print(\"5. README.md - Project documentation\")\n",
    "print()\n",
    "print(\"To run the Streamlit app:\")\n",
    "print(\"1. Open terminal in this directory\")\n",
    "print(\"2. Run: streamlit run streamlit_app.py\")\n",
    "print(\"3. Open browser to the provided URL\")\n",
    "print()\n",
    "print(\"Model Performance:\")\n",
    "print(\"- Accuracy: 100% on test data\")\n",
    "print(\"- Dataset: Iris flowers (150 samples)\")\n",
    "print(\"- Features: 4 measurements\")\n",
    "print(\"- Classes: 3 species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d26c5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final verification - All project files:\n",
      "==================================================\n",
      "✓ iris_model.pkl            (187297 bytes)\n",
      "✓ model_info.pkl            (458 bytes)\n",
      "✓ streamlit_app.py          (1603 bytes)\n",
      "✓ requirements.txt          (121 bytes)\n",
      "✓ README.md                 (1510 bytes)\n",
      "✓ test_model.py             (883 bytes)\n",
      "✓ PROJECT_REPORT.md         (4231 bytes)\n",
      "\n",
      "Project is ready for deployment!\n",
      "Run this command to start the web app:\n",
      "streamlit run streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "# Verify all files are created and show their sizes\n",
    "import os\n",
    "\n",
    "files_to_check = [\n",
    "    'iris_model.pkl',\n",
    "    'model_info.pkl', \n",
    "    'streamlit_app.py',\n",
    "    'requirements.txt',\n",
    "    'README.md',\n",
    "    'test_model.py',\n",
    "    'PROJECT_REPORT.md'\n",
    "]\n",
    "\n",
    "print(\"Final verification - All project files:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for file in files_to_check:\n",
    "    size = os.path.getsize(file) if os.path.exists(file) else 0\n",
    "    status = \"✓\" if os.path.exists(file) else \"✗\"\n",
    "    print(f\"{status} {file:<25} ({size} bytes)\")\n",
    "\n",
    "print(\"\\nProject is ready for deployment!\")\n",
    "print(\"Run this command to start the web app:\")\n",
    "print(\"streamlit run streamlit_app.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
